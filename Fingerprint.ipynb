{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b727b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.image import resize\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation, Add, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomZoom, RandomRotation, SeparableConv2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a706633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 16 15:15:05 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.14                 Driver Version: 566.14         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2070      WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   67C    P8              6W /  115W |       1MiB /   8192MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system('nvidia-smi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3519a8",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373de882",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./Data/GreenBit_Train_Original_Augmentation.hdf5', 'r') as hf:\n",
    "    X_train = hf.get('x_train')[:]\n",
    "    X_target = hf.get('x_target')[:]\n",
    "    \n",
    "with h5py.File('./Data/GreenBit_Test_Preprocessing.hdf5', 'r') as hf:\n",
    "    X_test = hf.get('x_test')[:]\n",
    "    X_label = hf.get('x_label')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a451828",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_target.shape)\n",
    "print(X_test.shape, X_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9002148",
   "metadata": {},
   "source": [
    "## Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d649e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train[0])\n",
    "display(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16812e",
   "metadata": {},
   "source": [
    "## image print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f86a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X_train[0], cmap='Greys')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(X_test[0], cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "print(X_target[0], X_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81dd516",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a1d7cb",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 하이퍼 파라미터 튜닝\n",
    "# img_size_h = 224\n",
    "# img_size_v = 224\n",
    "\n",
    "# batch_size = 128\n",
    "# epochs = 100\n",
    "# learning_rate = 1e-5\n",
    "\n",
    "# conv = 3\n",
    "# pool = 2\n",
    "\n",
    "# nb_class = 2\n",
    "\n",
    "# _optimizer = Nadam(learning_rate=learning_rate)\n",
    "\n",
    "# # 모델 쌓기\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Input(shape=(img_size_h, img_size_v, 1)))\n",
    "\n",
    "# model.add(Conv2D(32, (conv, conv), padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool), padding='same'))\n",
    "    \n",
    "# model.add(Conv2D(32, (conv, conv), padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool), padding='same'))\n",
    "    \n",
    "# model.add(Conv2D(64, (conv, conv), padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool), padding='same'))\n",
    "    \n",
    "# model.add(Conv2D(64, (conv, conv), padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool), padding='same'))\n",
    "\n",
    "# model.add(Conv2D(64, (conv, conv), padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool), padding='same'))\n",
    "\n",
    "# model.add(Conv2D(64, (conv, conv), padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool), padding='same'))\n",
    "    \n",
    "# model.add(Conv2D(128, (conv, conv), padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool)))\n",
    "    \n",
    "# model.add(Conv2D(128, (conv, conv), padding='same'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool)))\n",
    "# model.add(Dropout(0.3))\n",
    "    \n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, kernel_regularizer=regularizers.l2(learning_rate)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Dense(nb_class))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# # 모델의 실행 옵션을 설정합니다.\n",
    "# model.compile(loss='binary_crossentropy', optimizer=_optimizer, metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# model.save(\"./Model/GreenBit_Model.h5\")\n",
    "\n",
    "# hist = model.fit(X_train, X_target, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f267b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_train, X_target, batch_size=batch_size, verbose=0)\n",
    "print('Loss : {0:.4f}, Accuracy : {1:.4f} '.format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bf6eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:2'):\n",
    "score = model.evaluate(X_test, X_label, batch_size=batch_size, verbose=0)\n",
    "print('Accuracy : {:.4f} '.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae382c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63065a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd6527",
   "metadata": {},
   "source": [
    "## VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47df7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 하이퍼 파라미터 튜닝\n",
    "# img_size_h = 224\n",
    "# img_size_v = 224\n",
    "\n",
    "# batch_size = 128\n",
    "# epochs = 100\n",
    "# learning_rate = 1e-5\n",
    "\n",
    "# conv = 3\n",
    "# pool = 2\n",
    "\n",
    "# nb_class = 2\n",
    "\n",
    "# _optimizer = Nadam(learning_rate=learning_rate)\n",
    "\n",
    "# # 모델 쌓기\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Input(shape=(img_size_h, img_size_v, 1)))\n",
    "\n",
    "# model.add(Conv2D(64, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(64, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool), strides=2))\n",
    "    \n",
    "# model.add(Conv2D(128, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(128, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool), strides=2))\n",
    "\n",
    "# model.add(Conv2D(256, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(256, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(256, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool), strides=2))\n",
    "\n",
    "# model.add(Conv2D(512, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(512, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(512, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool), strides=2))\n",
    "\n",
    "# model.add(Conv2D(512, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(512, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Conv2D(512, (conv, conv), padding='same'))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(pool, pool), strides=2))\n",
    "    \n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(4096, kernel_regularizer=regularizers.l2(learning_rate)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(4096, kernel_regularizer=regularizers.l2(learning_rate)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Dense(nb_class))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# # 모델의 실행 옵션을 설정합니다.\n",
    "# model.compile(loss='binary_crossentropy', optimizer=_optimizer, metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# model.save(\"./Model/GreenBit_VGG_Model.h5\")\n",
    "\n",
    "# hist = model.fit(X_train, X_target, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ab4efc",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5954c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 하이퍼 파라미터 튜닝\n",
    "# img_size_h = 224\n",
    "# img_size_v = 224\n",
    "\n",
    "# batch_size = 128\n",
    "# epochs = 100\n",
    "# learning_rate = 1e-5\n",
    "\n",
    "# conv = 3\n",
    "# pool = 2\n",
    "\n",
    "# nb_class = 2\n",
    "\n",
    "# _optimizer = Nadam(learning_rate=learning_rate)\n",
    "\n",
    "# # layer function\n",
    "# def first_convolution(input_tensor):\n",
    "#     x = ZeroPadding2D(padding=(3, 3))(input_tensor)\n",
    "#     x = Conv2D(filters=64, strides=(2, 2), kernel_size=(7,7))(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "#     return x\n",
    "\n",
    "# def first_pooling(input_tensor):\n",
    "#     x = ZeroPadding2D(padding=(1, 1))(input_tensor)\n",
    "#     x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "#     return x\n",
    "\n",
    "# def residual_block(input_tensor, kernel_size, num_filters):\n",
    "#     x = Conv2D(kernel_size=(1, 1), filters=num_filters//4)(input_tensor)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "#     x = Conv2D(kernel_size=kernel_size, filters=num_filters//4, padding='same')(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "#     x = Conv2D(kernel_size=(1, 1), filters=num_filters)(x)\n",
    "#     x = Add()([input_tensor, x])\n",
    "    \n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "#     return x\n",
    "\n",
    "# def downsize_block(input_tensor, kernel_size, strides, num_filters):\n",
    "#     x = Conv2D(kernel_size=(1, 1), filters=num_filters//4, strides=strides)(input_tensor)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "#     x = Conv2D(kernel_size=kernel_size, filters=num_filters//4, padding='same')(x)\n",
    "#     x = Activation('relu')(x)\n",
    "    \n",
    "#     x = Conv2D(kernel_size=(1, 1), filters=num_filters)(x)\n",
    "    \n",
    "#     shortcut = Conv2D(kernel_size=(1, 1), filters=num_filters, strides=strides)(input_tensor)\n",
    "    \n",
    "#     x = Add()([shortcut, x])\n",
    "#     output_tensor = Activation('relu')(x)\n",
    "    \n",
    "#     return output_tensor\n",
    "\n",
    "# # 모델 쌓기\n",
    "# input_tensor = Input(shape=(224, 224, 1))\n",
    "\n",
    "# x = first_convolution(input_tensor)\n",
    "\n",
    "# x = first_pooling(x)\n",
    "# x = downsize_block(x, (3, 3), (1, 1), 256)\n",
    "# x = residual_block(x, (3, 3), 256)\n",
    "# x = residual_block(x, (3, 3), 256)\n",
    "\n",
    "# x = downsize_block(x, (3, 3), (2, 2), 512)\n",
    "# x = residual_block(x, (3, 3), 512)\n",
    "# x = residual_block(x, (3, 3), 512)\n",
    "# x = residual_block(x, (3, 3), 512)\n",
    "\n",
    "# x = downsize_block(x, (3, 3), (2, 2), 1024)\n",
    "# x = residual_block(x, (3, 3), 1024)\n",
    "# x = residual_block(x, (3, 3), 1024)\n",
    "# x = residual_block(x, (3, 3), 1024)\n",
    "# x = residual_block(x, (3, 3), 1024)\n",
    "# x = residual_block(x, (3, 3), 1024)\n",
    "\n",
    "# x = downsize_block(x, (3, 3), (2, 2), 2048)\n",
    "# x = residual_block(x, (3, 3), 2048)\n",
    "# x = residual_block(x, (3, 3), 2048)\n",
    "\n",
    "# x = GlobalMaxPooling2D()(x)\n",
    "# x = Dense(nb_class, activation='sigmoid')(x)\n",
    "\n",
    "# model = Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "# # 모델의 실행 옵션을 설정합니다.\n",
    "# model.compile(loss='binary_crossentropy', optimizer=_optimizer, metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# model.save(\"./Model/GreenBit_ResNet_Model.h5\")\n",
    "\n",
    "# hist = model.fit(X_train, X_target, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe916556",
   "metadata": {},
   "source": [
    "## SlimResCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 튜닝\n",
    "img_size_h = 224\n",
    "img_size_v = 224\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "learning_rate = 1e-5\n",
    "\n",
    "conv = 3\n",
    "pool = 2\n",
    "\n",
    "nb_class = 2\n",
    "\n",
    "_optimizer = Nadam(learning_rate=learning_rate)\n",
    "\n",
    "# layer function\n",
    "def first_convolution(input_tensor):\n",
    "    x = Conv2D(filters=32, kernel_size=3, strides=1, padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def residual_block_type_B(input_tensor, out_channal):\n",
    "    x = Conv2D(filters=out_channal, kernel_size=3, strides=1, padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv2D(filters=out_channal, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def downsize_block_type_B(input_tensor, out_channal):\n",
    "    x = Conv2D(filters=out_channal, kernel_size=3, strides=2)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv2D(filters=out_channal, kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def Slim_Res_CNN():\n",
    "    input_tensor = Input(shape=(None,None,1))\n",
    "    \n",
    "    conv1 = first_convolution(input_tensor)\n",
    "    \n",
    "    conv2 = residual_block_type_B(conv1, 32)\n",
    "    conv2 = residual_block_type_B(conv2, 32)\n",
    "    conv2 = residual_block_type_B(conv2, 32)\n",
    "    \n",
    "    conv3_1 = downsize_block_type_B(conv2, 64)\n",
    "    conv3_2 = residual_block_type_B(conv3_1, 64)\n",
    "    conv3_2 = residual_block_type_B(conv3_2, 64)\n",
    "    \n",
    "    conv4_1 = downsize_block_type_B(conv3_2, 128)\n",
    "    conv4_2 = residual_block_type_B(conv4_1, 128)\n",
    "    conv4_2 = residual_block_type_B(conv4_2, 128)\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling2D()(conv4_2)\n",
    "    out = Dense(nb_class, activation='sigmoid')(avg_pool)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d18256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # layer function\n",
    "# def conv3x3(x, out_channel, strides):\n",
    "#     x = tf.keras.layers.Conv2D(out_channel, kernel_size=3,strides=strides,padding='same')(x)\n",
    "\n",
    "#     return x\n",
    "\n",
    "# def conv3x3_with_dropout(x, out_channel, strides):\n",
    "#     x = conv3x3(x, out_channel, strides)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = tf.keras.layers.Activation('relu')(x)\n",
    "     \n",
    "#     return x\n",
    "\n",
    "# def pad_depth(x, desired_channels):\n",
    "#     new_channels = desired_channels - x.shape.as_list()[-1]\n",
    "#     output = tf.identity(x)\n",
    "#     repetitions = new_channels/x.shape.as_list()[-1]\n",
    "#     for _ in range(int(repetitions)):\n",
    "#         zeroTensors = tf.zeros_like(x, name='pad_depth1')\n",
    "#         output = tf.keras.backend.concatenate([output, zeroTensors])\n",
    "#     return output\n",
    "\n",
    "# def Resblock(inputs, out_channel,downsample=False):\n",
    "    \n",
    "#     if downsample:\n",
    "#         x = conv3x3_with_dropout(inputs, out_channel,strides=2)\n",
    "#         x = conv3x3(x, out_channel,strides=1)\n",
    "        \n",
    "#         down_sampled = tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2)(inputs)\n",
    "#         equal = pad_depth(down_sampled,out_channel)\n",
    "        \n",
    "#         out = tf.keras.layers.Add()([x,equal])\n",
    "        \n",
    "#     else:\n",
    "#         x = conv3x3_with_dropout(inputs, out_channel,strides=1)\n",
    "#         x = conv3x3(x, out_channel, strides=1)\n",
    "        \n",
    "#         out = tf.keras.layers.Add()([x, inputs])\n",
    "        \n",
    "#     return out\n",
    "\n",
    "# def Conv1(x):\n",
    "#     x = conv3x3(x,32,strides=1)\n",
    "#     x = tf.keras.layers.Activation('relu')(x)\n",
    "#     return x\n",
    "\n",
    "# def Conv2(x):\n",
    "#     for i in range(3):\n",
    "#         x = Resblock(x, 32)\n",
    "#     return x\n",
    "\n",
    "# def Conv3(x):\n",
    "#     x = Resblock(x, 64, True)\n",
    "#     for i in range(2):\n",
    "#         x = Resblock(x, 64)\n",
    "#     return x\n",
    "\n",
    "# def Conv4(x):\n",
    "#     x = Resblock(x, 128, True)\n",
    "#     for i in range(2):\n",
    "#         x = Resblock(x, 128)\n",
    "#     return x\n",
    "\n",
    "# def GAP(x):\n",
    "#     gap = tf.reduce_mean(x, axis=[1,2],keepdims=True)\n",
    "#     return gap\n",
    "\n",
    "# def SlimResNet():\n",
    "#     inputs = Input(shape=(None,None,1))\n",
    "    \n",
    "#     conv1 = Conv1(inputs)\n",
    "#     conv2 = Conv2(conv1)\n",
    "#     conv3 = Conv3(conv2)\n",
    "#     conv4 = Conv4(conv3)\n",
    "    \n",
    "#     x = tf.keras.layers.GlobalAveragePooling2D()(conv4)\n",
    "#     out = tf.keras.layers.Dense(2,activation='softmax')(x)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "    \n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Slim_Res_CNN()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=_optimizer, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.save(\"./Model/GreenBit_SlimResNet_Model.h5\")\n",
    "\n",
    "hist = model.fit(X_train, X_target, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i in range(len(test)):\n",
    "    print(f\"{i+1}번째 Test Data의 실제 값 : {X_label[i][1]}\")\n",
    "    print(f\"{i+1}번째 Test Data의 예측 값 : {test[i][1]:.4f}\")\n",
    "    if X_label[i][1] == 1:\n",
    "        if test[i][1] >= 0.5:\n",
    "            cnt += 1\n",
    "    else:\n",
    "        if test[i][1] < 0.5:\n",
    "            cnt += 1\n",
    "\n",
    "print(f\"{cnt / len(test):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
